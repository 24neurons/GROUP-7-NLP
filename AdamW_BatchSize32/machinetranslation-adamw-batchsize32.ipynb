{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11757372,"sourceType":"datasetVersion","datasetId":7381006},{"sourceId":11817131,"sourceType":"datasetVersion","datasetId":7422396}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets laonlp underthesea","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nimport torch.nn.functional as F\nfrom laonlp import word_tokenize as lao_tokenize\nfrom typing import Dict, List, Tuple\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport logging\nfrom tqdm import tqdm\nimport math\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom underthesea import word_tokenize as vi_tokenize\n\n# Thiết lập logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# Thiết lập seed cho việc tái tạo kết quả\nSEED = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# Các tham số cho mô hình\nMAX_LENGTH = 128\nBATCH_SIZE = 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 1e-4\nEMBEDDING_DIM = 768\nFFN_HIDDEN_DIM = 3072\nNUM_ENCODER_LAYERS = 8\nNUM_DECODER_LAYERS = 8\nNUM_ATTENTION_HEADS = 12\nDROPOUT = 0.05\n\nVI_TRAIN_PATH = \"/kaggle/input/vi-lo-dataset/train2023.vi\"\nLAO_TRAIN_PATH = \"/kaggle/input/vi-lo-dataset/train2023.lo\"\n\nVI_VAL_PATH = \"/kaggle/input/vi-lo-dataset/dev2023.vi\"\nLAO_VAL_PATH = \"/kaggle/input/vi-lo-dataset/dev2023.lo\"\n\nVI_TEST_PATH = \"/kaggle/input/vi-lo-dataset/test_vi.txt\"\nLAO_TEST_PATH = \"/kaggle/input/vi-lo-dataset/test_lo.txt\"\n\nOUTPUT_DIR = \"machine_translation_model\"\n\ndef vi_tokenizer(text):\n    return vi_tokenize(text, format=\"text\").split()\n\n# Lớp xử lý từ vựng cho Transformer\nclass Vocabulary:\n\n    def __init__(self, pad_token=\"<pad>\", unk_token=\"<unk>\",\n                 sos_token=\"<sos>\", eos_token=\"<eos>\"):\n        self.word2idx = {}\n        self.idx2word = {}\n        self.freq = {}\n\n        # Thêm các token đặc biệt\n        self.pad_token = pad_token\n        self.unk_token = unk_token\n        self.sos_token = sos_token\n        self.eos_token = eos_token\n\n        # Khởi tạo với các token đặc biệt\n        self.add_word(self.pad_token)\n        self.add_word(self.unk_token)\n        self.add_word(self.sos_token)\n        self.add_word(self.eos_token)\n\n    def add_word(self, word):\n        if word not in self.word2idx:\n            idx = len(self.word2idx)\n            self.word2idx[word] = idx\n            self.idx2word[idx] = word\n            self.freq[word] = 1\n        else:\n            self.freq[word] += 1\n\n    def __len__(self):\n        return len(self.word2idx)\n\n    def encode(self, text, tokenizer_func=None, max_length=None):\n        # Chuyển đổi text thành chuỗi các chỉ số\n        if tokenizer_func:\n            tokens = tokenizer_func(text)\n        else:\n            tokens = text.split()\n\n        # Thêm token bắt đầu và kết thúc\n        tokens = [self.sos_token] + tokens + [self.eos_token]\n\n        # Cắt bớt nếu vượt quá độ dài tối đa\n        if max_length and len(tokens) > max_length:\n            tokens = tokens[:max_length-1] + [self.eos_token]\n\n        # Chuyển đổi thành chỉ số\n        indices = [self.word2idx.get(token, self.word2idx[self.unk_token])\n                   for token in tokens]\n\n        # Padding nếu cần\n        if max_length and len(indices) < max_length:\n            indices += [self.word2idx[self.pad_token]] * (max_length - len(indices))\n\n        return indices\n\n    def decode(self, indices):\n        \"\"\"Chuyển đổi chuỗi chỉ số thành text\"\"\"\n        tokens = [self.idx2word.get(idx, self.unk_token) for idx in indices]\n\n        # Loại bỏ các token đặc biệt\n        valid_tokens = []\n        for token in tokens:\n            if token == self.eos_token:\n                break\n            if token not in [self.pad_token, self.sos_token]:\n                valid_tokens.append(token)\n\n        return ' '.join(valid_tokens)\n\n    def build_vocab(self, texts, tokenizer_func=None, min_freq=2):\n        \"\"\"Xây dựng từ vựng từ danh sách các văn bản\"\"\"\n        for text in tqdm(texts, desc=\"Xây dựng từ vựng\"):\n            if tokenizer_func:\n                tokens = tokenizer_func(text)\n            else:\n                tokens = text.split()\n\n            for token in tokens:\n                self.add_word(token)\n\n        # Giữ lại các từ có tần suất >= min_freq\n        if min_freq > 1:\n            new_word2idx = {self.pad_token: 0, self.unk_token: 1,\n                            self.sos_token: 2, self.eos_token: 3}\n            new_idx2word = {0: self.pad_token, 1: self.unk_token,\n                            2: self.sos_token, 3: self.eos_token}\n\n            idx = len(new_word2idx)\n            for word, freq in self.freq.items():\n                if freq >= min_freq and word not in new_word2idx:\n                    new_word2idx[word] = idx\n                    new_idx2word[idx] = word\n                    idx += 1\n\n            self.word2idx = new_word2idx\n            self.idx2word = new_idx2word\n\n        logger.info(f\"Kích thước từ vựng sau khi lọc (min_freq={min_freq}): {len(self.word2idx)}\")\n\n\n\"\"\"Dataset cho nhiệm vụ dịch máy\"\"\"\nclass TranslationDataset(Dataset):\n\n    def __init__(self, source_texts, target_texts, source_vocab, target_vocab,\n                 source_tokenizer=None, target_tokenizer=None, max_length=MAX_LENGTH):\n        self.source_texts = source_texts\n        self.target_texts = target_texts\n        self.source_vocab = source_vocab\n        self.target_vocab = target_vocab\n        self.source_tokenizer = source_tokenizer\n        self.target_tokenizer = target_tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.source_texts)\n\n    def __getitem__(self, idx):\n        source_text = self.source_texts[idx]\n        target_text = self.target_texts[idx]\n\n        # Encode source và target\n        source_indices = self.source_vocab.encode(\n            source_text,\n            self.source_tokenizer,\n            self.max_length\n        )\n\n        target_indices = self.target_vocab.encode(\n            target_text,\n            self.target_tokenizer,\n            self.max_length\n        )\n\n        # Chuyển đổi sang tensor\n        source_tensor = torch.tensor(source_indices, dtype=torch.long)\n        target_tensor = torch.tensor(target_indices, dtype=torch.long)\n\n        return {\n            \"source\": source_tensor,\n            \"target\": target_tensor,\n            \"source_text\": source_text,\n            \"target_text\": target_text\n        }\n\n\n\"\"\"Mã hóa vị trí cho transformer\"\"\"\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, max_len=5000, dropout=0.1):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        # Tính toán positional encoding\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(0), :]\n        return self.dropout(x)\n\n\"\"\"Khởi tạo mô hình Transformer\"\"\"\nclass CustomTransformer(nn.Module):\n\n    def __init__(\n        self,\n        source_vocab_size,\n        target_vocab_size,\n        d_model=512,\n        nhead=8,\n        num_encoder_layers=6,\n        num_decoder_layers=6,\n        dim_feedforward=2048,\n        dropout=0.1,\n        pad_idx=0\n    ):\n        super(CustomTransformer, self).__init__()\n\n        self.d_model = d_model\n        self.pad_idx = pad_idx\n\n        # Embedding layers\n        self.source_embedding = nn.Embedding(source_vocab_size, d_model, padding_idx=pad_idx)\n        self.target_embedding = nn.Embedding(target_vocab_size, d_model, padding_idx=pad_idx)\n\n        # Positional encoding\n        self.positional_encoding = PositionalEncoding(d_model, dropout=dropout)\n\n        # Transformer layers\n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=False # Note: PyTorch Transformer expects seq_len first\n        )\n\n        # Output layer\n        self.fc_out = nn.Linear(d_model, target_vocab_size)\n\n    def create_mask(self, src, tgt):\n        # Tạo padding mask cho source\n        src_padding_mask = (src == self.pad_idx) # Expected shape (N, S)\n\n        # Tạo padding mask cho target\n        tgt_padding_mask = (tgt == self.pad_idx) # Expected shape (N, T)\n\n        # Tạo causal mask cho target (để tránh nhìn vào tương lai)\n        tgt_len = tgt.shape[1]\n        tgt_causal_mask = torch.triu(torch.ones((tgt_len, tgt_len), device=tgt.device) == 1).transpose(0, 1)\n        tgt_causal_mask = tgt_causal_mask.float().masked_fill(\n            tgt_causal_mask == 0, float('-inf')).masked_fill(tgt_causal_mask == 1, float(0.0))\n        # This causal mask is for nn.TransformerDecoderLayer if used directly\n        # For nn.Transformer, it handles causal mask internally via tgt_mask argument.\n\n        return src_padding_mask, tgt_padding_mask, tgt_causal_mask\n\n\n    def forward(self, src, tgt):\n        # Chuyển đổi batch_size x seq_len -> seq_len x batch_size\n        src = src.transpose(0, 1)\n        tgt = tgt.transpose(0, 1)\n\n        # Tạo các mask\n        # src_key_padding_mask should be (N, S) where N is batch_size, S is sequence length\n        src_padding_mask = (src == self.pad_idx).transpose(0,1)\n        # tgt_key_padding_mask should be (N, T)\n        tgt_padding_mask = (tgt == self.pad_idx).transpose(0,1)\n\n\n        # Tạo causal mask cho decoder\n        # tgt_mask should be (T, T) where T is target sequence length\n        tgt_len = tgt.size(0)\n        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_len).to(tgt.device)\n\n        # Áp dụng embedding và positional encoding\n        # Input to embedding is (S, N) or (T, N)\n        src_embedded = self.positional_encoding(self.source_embedding(src) * math.sqrt(self.d_model))\n        tgt_embedded = self.positional_encoding(self.target_embedding(tgt) * math.sqrt(self.d_model))\n\n        # Đưa qua transformer\n        # src: (S, N, E), tgt: (T, N, E)\n        # src_key_padding_mask: (N, S), tgt_key_padding_mask: (N, T)\n        # memory_key_padding_mask: (N, S)\n        # tgt_mask: (T,T)\n        output = self.transformer(\n            src_embedded,\n            tgt_embedded,\n            src_key_padding_mask=src_padding_mask,\n            tgt_key_padding_mask=tgt_padding_mask,\n            memory_key_padding_mask=src_padding_mask, # Use src_padding_mask for memory\n            tgt_mask=tgt_mask\n        )\n\n        # Đưa qua lớp output\n        # output: (T, N, E)\n        output = self.fc_out(output) # output: (T, N, target_vocab_size)\n\n        # Chuyển lại về batch_size x seq_len x vocab_size\n        output = output.transpose(0, 1) # output: (N, T, target_vocab_size)\n\n        return output\n\n\"\"\"Khởi tạo bộ xử lý dữ liệu\"\"\"\nclass TranslationDataProcessor:\n\n    def __init__(self):\n        # Khởi tạo bộ từ vựng cho Việt và Lào\n        self.vi_vocab = Vocabulary()\n        self.lao_vocab = Vocabulary()\n\n    def _load_data_from_path(self, vi_path, lao_path, data_type=\"Training\") -> Tuple[List[str], List[str]]:\n        \"\"\"Đọc dữ liệu từ các file path cụ thể\"\"\"\n        logger.info(f\"Đọc dữ liệu {data_type}\")\n        try:\n            with open(vi_path, 'r', encoding='utf-8') as f:\n                vi_texts = f.readlines()\n            with open(lao_path, 'r', encoding='utf-8') as f:\n                lao_texts = f.readlines()\n        except FileNotFoundError as e:\n            logger.error(f\"Lỗi không tìm thấy file: {e}. Kiểm tra lại đường dẫn.\")\n            raise\n        except Exception as e:\n            logger.error(f\"Lỗi khi đọc file: {e}\")\n            raise\n\n\n        # Làm sạch dữ liệu\n        vi_texts = [text.strip() for text in vi_texts if text.strip()]\n        lao_texts = [text.strip() for text in lao_texts if text.strip()]\n\n        if not vi_texts or not lao_texts:\n            logger.warning(f\"Một trong các file dữ liệu {data_type} rỗng sau khi làm sạch: VI: {len(vi_texts)}, LAO: {len(lao_texts)}\")\n            # Return empty lists if data is empty to avoid assertion error for empty files.\n            # Or handle this case more specifically if empty datasets are not allowed.\n            return [], []\n\n\n        assert len(vi_texts) == len(lao_texts), \\\n            f\"Số lượng câu tiếng Việt ({len(vi_texts)}) và tiếng Lào ({len(lao_texts)}) trong tập {data_type} phải bằng nhau. \"\\\n            f\"VI file: {vi_path}, LAO file: {lao_path}\"\n\n\n        logger.info(f\"Tổng số cặp câu {data_type}: {len(vi_texts)}\")\n        return vi_texts, lao_texts\n\n    def build_vocabularies(self, train_vi_texts, train_lao_texts, min_freq=2):\n        \"\"\"Xây dựng từ vựng CHỈ từ dữ liệu huấn luyện\"\"\"\n        logger.info(\"Xây dựng từ vựng tiếng Việt từ tập huấn luyện\")\n        self.vi_vocab.build_vocab(train_vi_texts, tokenizer_func=lambda x: x.split(), min_freq=min_freq)\n\n        logger.info(\"Xây dựng từ vựng tiếng Lào từ tập huấn luyện\")\n        self.lao_vocab.build_vocab(train_lao_texts, tokenizer_func=lao_tokenize, min_freq=min_freq)\n\n        logger.info(f\"Kích thước từ vựng tiếng Việt: {len(self.vi_vocab)}\")\n        logger.info(f\"Kích thước từ vựng tiếng Lào: {len(self.lao_vocab)}\")\n\n    def create_datasets(self) -> Tuple[TranslationDataset, TranslationDataset, TranslationDataset]:\n        \"\"\"Tạo bộ dữ liệu huấn luyện, kiểm định và kiểm tra từ các file riêng biệt\"\"\"\n        # Đọc dữ liệu huấn luyện\n        train_vi_texts, train_lao_texts = self._load_data_from_path(VI_TRAIN_PATH, LAO_TRAIN_PATH, \"Training\")\n\n        # Xây dựng từ vựng CHỈ từ dữ liệu huấn luyện\n        self.build_vocabularies(train_vi_texts, train_lao_texts)\n\n        # Đọc dữ liệu kiểm định (validation)\n        val_vi_texts, val_lao_texts = self._load_data_from_path(VI_VAL_PATH, LAO_VAL_PATH, \"Validation\")\n\n        # Đọc dữ liệu kiểm tra (test)\n        test_vi_texts, test_lao_texts = self._load_data_from_path(VI_TEST_PATH, LAO_TEST_PATH, \"Test\")\n\n\n        # Tạo các dataset\n        train_dataset = TranslationDataset(\n            train_vi_texts, train_lao_texts, self.vi_vocab, self.lao_vocab,\n            source_tokenizer=vi_tokenizer,\n            target_tokenizer=lao_tokenize,\n            max_length=MAX_LENGTH\n        )\n\n        val_dataset = TranslationDataset(\n            val_vi_texts, val_lao_texts, self.vi_vocab, self.lao_vocab,\n            source_tokenizer=vi_tokenizer,\n            target_tokenizer=lao_tokenize,\n            max_length=MAX_LENGTH\n        )\n\n        test_dataset = TranslationDataset(\n            test_vi_texts, test_lao_texts, self.vi_vocab, self.lao_vocab,\n            source_tokenizer=vi_tokenizer,\n            target_tokenizer=lao_tokenize,\n            max_length=MAX_LENGTH\n        )\n\n        logger.info(f\"Số mẫu huấn luyện: {len(train_dataset)}\")\n        logger.info(f\"Số mẫu kiểm định: {len(val_dataset)}\")\n        logger.info(f\"Số mẫu kiểm tra: {len(test_dataset)}\")\n\n        # Kiểm tra xem có dataset nào rỗng không\n        if len(train_dataset) == 0:\n            logger.error(\"Tập huấn luyện rỗng. Vui lòng kiểm tra lại đường dẫn và nội dung file.\")\n            raise ValueError(\"Tập huấn luyện không được rỗng.\")\n        if len(val_dataset) == 0:\n            logger.warning(\"Tập kiểm định rỗng. Tiếp tục mà không có kiểm định có thể không lý tưởng.\")\n        if len(test_dataset) == 0:\n            logger.warning(\"Tập kiểm tra rỗng.\")\n\n\n        return train_dataset, val_dataset, test_dataset\n\n\ndef train_epoch(model, data_loader, optimizer, criterion, scheduler, device):\n    model.train()\n    epoch_loss = 0\n\n    for batch in tqdm(data_loader, desc=\"Training\"):\n        # Đưa dữ liệu lên device\n        src = batch[\"source\"].to(device)\n        tgt = batch[\"target\"].to(device)\n\n        # Teacher forcing:\n        # tgt_input là target dịch sang phải 1 vị trí, bắt đầu bằng <sos>\n        # tgt_output là target gốc, bỏ <sos> ở đầu\n        tgt_input = tgt[:, :-1]\n        tgt_output = tgt[:, 1:]\n\n        # Xóa gradient từ batch trước\n        optimizer.zero_grad()\n\n        # Forward pass\n        # output shape: (batch_size, tgt_len -1, target_vocab_size)\n        output = model(src, tgt_input)\n\n\n        # Tính loss (bỏ qua padding)\n        # output: (batch_size * (tgt_len-1), target_vocab_size)\n        # tgt_output: (batch_size * (tgt_len-1))\n        output_dim = output.shape[-1]\n        output = output.contiguous().view(-1, output_dim)\n        tgt_output = tgt_output.contiguous().view(-1)\n\n\n        # Tính loss và thực hiện backpropagation\n        loss = criterion(output, tgt_output)\n        loss.backward()\n\n        # Cập nhật tham số\n        optimizer.step()\n\n        scheduler.step()\n\n        # Cập nhật loss\n        epoch_loss += loss.item()\n\n    return epoch_loss / len(data_loader)\n\n\n\"\"\"Hàm đánh giá\"\"\"\ndef evaluate(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            # Đưa dữ liệu lên device\n            src = batch[\"source\"].to(device)\n            tgt = batch[\"target\"].to(device)\n\n            # Teacher forcing\n            tgt_input = tgt[:, :-1]\n            tgt_output = tgt[:, 1:]\n\n            # Forward pass\n            output = model(src, tgt_input)\n\n            # Tính loss\n            output_dim = output.shape[-1]\n            output = output.contiguous().view(-1, output_dim)\n            tgt_output = tgt_output.contiguous().view(-1)\n\n            loss = criterion(output, tgt_output)\n\n            # Cập nhật loss\n            epoch_loss += loss.item()\n\n    if len(data_loader) == 0:\n        logger.warning(\"DataLoader for evaluation is empty. Returning loss as 0.\")\n        return 0\n    return epoch_loss / len(data_loader)\n\n\n\"\"\"Hàm dịch một câu\"\"\"\ndef translate_sentence(model, sentence, source_vocab, target_vocab, device, max_length=MAX_LENGTH, source_tokenizer=None):\n    # Chuyển sang chế độ evaluation\n    model.eval()\n\n    # Tokenize và encode câu nguồn\n    if source_tokenizer:\n        tokens = source_tokenizer(sentence)\n    else:\n        tokens = sentence.split()\n\n    # Thêm token bắt đầu và kết thúc\n    tokens = [source_vocab.sos_token] + tokens + [source_vocab.eos_token]\n\n    # Chuyển thành chỉ số\n    src_indices = [source_vocab.word2idx.get(token, source_vocab.word2idx[source_vocab.unk_token])\n                   for token in tokens]\n\n    # Chuyển sang tensor và đưa lên device (batch_size = 1)\n    # src_tensor shape: (1, src_len)\n    src_tensor = torch.LongTensor(src_indices).unsqueeze(0).to(device)\n\n\n    # ----- Encoder -----\n    # src for embedding: (src_len, 1)\n    src_emb_input = src_tensor.transpose(0,1)\n    src_padding_mask_for_encoder = (src_tensor == source_vocab.word2idx[source_vocab.pad_token]) # shape (1, src_len)\n    src_embedded = model.positional_encoding(model.source_embedding(src_emb_input) * math.sqrt(model.d_model))\n    encoder_output = model.transformer.encoder(src_embedded, src_key_padding_mask=src_padding_mask_for_encoder)\n    # encoder_output shape: (src_len, 1, d_model)\n\n    # ----- Decoder -----\n    # Bắt đầu với token SOS\n    tgt_indices = [target_vocab.word2idx[target_vocab.sos_token]]\n\n    # Thực hiện dịch\n    for i in range(max_length):\n        # Chuyển target thành tensor (batch_size = 1)\n        # tgt_tensor_input shape: (1, current_tgt_len)\n        tgt_tensor_input = torch.LongTensor(tgt_indices).unsqueeze(0).to(device)\n\n        # tgt for embedding: (current_tgt_len, 1)\n        tgt_emb_input = tgt_tensor_input.transpose(0,1)\n\n        # Tạo mask cho target (causal mask)\n        # tgt_mask_for_decoder shape: (current_tgt_len, current_tgt_len)\n        tgt_mask_for_decoder = model.transformer.generate_square_subsequent_mask(len(tgt_indices)).to(device)\n        # No padding mask for target during inference as we generate one token at a time\n\n        tgt_embedded = model.positional_encoding(model.target_embedding(tgt_emb_input) * math.sqrt(model.d_model))\n\n        # Decoder\n        # memory_key_padding_mask is src_padding_mask_for_encoder (N, S) -> (1, src_len)\n        decoder_output = model.transformer.decoder(\n            tgt_embedded, encoder_output,\n            tgt_mask=tgt_mask_for_decoder,\n            memory_key_padding_mask=src_padding_mask_for_encoder\n        )\n        # decoder_output shape: (current_tgt_len, 1, d_model)\n\n        # Dự đoán token tiếp theo từ output của token cuối cùng trong chuỗi target hiện tại\n        # prediction shape: (1, d_model)\n        prediction = model.fc_out(decoder_output[-1, :, :]) # Lấy output của token cuối cùng\n        # prediction shape after fc_out: (1, target_vocab_size)\n\n        next_token = prediction.argmax(1).item()\n\n        # Thêm token vào kết quả\n        tgt_indices.append(next_token)\n\n        # Nếu gặp token kết thúc thì dừng\n        if next_token == target_vocab.word2idx[target_vocab.eos_token]:\n            break\n\n    # Chuyển đổi chỉ số thành văn bản\n    tgt_tokens = [target_vocab.idx2word.get(idx, target_vocab.unk_token) for idx in tgt_indices]\n\n    # Loại bỏ các token đặc biệt (chỉ <sos> ở đầu và <eos> nếu có ở cuối)\n    if tgt_tokens and tgt_tokens[0] == target_vocab.sos_token:\n        tgt_tokens = tgt_tokens[1:]\n    if tgt_tokens and tgt_tokens[-1] == target_vocab.eos_token:\n        tgt_tokens = tgt_tokens[:-1]\n\n    # Nối các token để tạo câu\n    return ' '.join(tgt_tokens)\n\n\"\"\"Hàm huấn luyện mô hình\"\"\"\ndef train_model(data_processor, train_dataset, val_dataset, test_dataset):\n    # Thiết lập device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    logger.info(f\"Sử dụng device: {device}\")\n\n    # Tạo DataLoader\n    if len(train_dataset) == 0:\n        logger.error(\"Không thể tạo DataLoader cho tập huấn luyện rỗng.\")\n        return None, data_processor\n\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=2\n    )\n\n    val_loader = None\n    if val_dataset and len(val_dataset) > 0:\n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=BATCH_SIZE,\n            shuffle=False,\n            num_workers=2\n        )\n    else:\n        logger.warning(\"Tập kiểm định rỗng, bỏ qua DataLoader kiểm định.\")\n\n\n    test_loader = None\n    if test_dataset and len(test_dataset) > 0:\n        test_loader = DataLoader(\n            test_dataset,\n            batch_size=BATCH_SIZE,\n            shuffle=False,\n            num_workers=2\n        )\n    else:\n        logger.warning(\"Tập kiểm tra rỗng, bỏ qua DataLoader kiểm tra.\")\n\n\n    # Khởi tạo mô hình\n    source_pad_idx = data_processor.vi_vocab.word2idx[data_processor.vi_vocab.pad_token]\n    model = CustomTransformer(\n        source_vocab_size=len(data_processor.vi_vocab),\n        target_vocab_size=len(data_processor.lao_vocab),\n        d_model=EMBEDDING_DIM,\n        nhead=NUM_ATTENTION_HEADS,\n        num_encoder_layers=NUM_ENCODER_LAYERS,\n        num_decoder_layers=NUM_DECODER_LAYERS,\n        dim_feedforward=FFN_HIDDEN_DIM,\n        dropout=DROPOUT,\n        pad_idx=source_pad_idx # pad_idx for source embedding and mask creation\n    ).to(device)\n\n    # Tổng số tham số\n    total_params = sum(p.numel() for p in model.parameters())\n    logger.info(f\"Tổng số tham số của mô hình: {total_params:,}\")\n\n    # Khởi tạo optimizer và loss function\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n\n    scheduler = OneCycleLR(\n        optimizer,\n        max_lr=LEARNING_RATE,\n        total_steps=NUM_EPOCHS * len(train_loader),\n        pct_start=0.1,\n        anneal_strategy='linear'\n    )  \n\n    # ignore_index cho loss là padding token của target vocab\n    target_pad_idx = data_processor.lao_vocab.word2idx[data_processor.lao_vocab.pad_token]\n    criterion = nn.CrossEntropyLoss(ignore_index=target_pad_idx)\n\n\n    # Lưu trữ lịch sử huấn luyện\n    train_losses = []\n    val_losses = []\n    best_val_loss = float('inf')\n\n    # Huấn luyện\n    for epoch in range(NUM_EPOCHS):\n        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n\n        # Huấn luyện một epoch\n        train_loss = train_epoch(model, train_loader, optimizer, criterion, scheduler, device)\n        train_losses.append(train_loss)\n        print(f\"Train Loss: {train_loss:.4f}\")\n\n        # Đánh giá trên tập validation\n        if val_loader:\n            val_loss = evaluate(model, val_loader, criterion, device)\n            val_losses.append(val_loss)\n            print(f\"Validation Loss: {val_loss:.4f}\")\n\n            # Lưu mô hình tốt nhất\n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'vi_vocab': data_processor.vi_vocab,\n                    'lao_vocab': data_processor.lao_vocab,\n                    'train_loss': train_loss,\n                    'val_loss': val_loss,\n                    'source_pad_idx': source_pad_idx,\n                    'target_pad_idx': target_pad_idx,\n                    'model_params': { # Lưu các tham số cấu hình mô hình\n                        'source_vocab_size':len(data_processor.vi_vocab),\n                        'target_vocab_size':len(data_processor.lao_vocab),\n                        'd_model':EMBEDDING_DIM,\n                        'nhead':NUM_ATTENTION_HEADS,\n                        'num_encoder_layers':NUM_ENCODER_LAYERS,\n                        'num_decoder_layers':NUM_DECODER_LAYERS,\n                        'dim_feedforward':FFN_HIDDEN_DIM,\n                        'dropout':DROPOUT,\n                        'pad_idx':source_pad_idx\n                    }\n                }, os.path.join(OUTPUT_DIR, 'best_model.pt'))\n                print(\"Đã lưu mô hình tốt nhất!\")\n\n    # Vẽ biểu đồ loss\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_losses, label='Train Loss')\n    if val_losses:\n        plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training and Validation Loss History')\n    plt.savefig(os.path.join(OUTPUT_DIR, 'loss_history.png'))\n    logger.info(f\"Đã lưu biểu đồ loss tại: {os.path.join(OUTPUT_DIR, 'loss_history.png')}\")\n\n\n    # Đánh giá mô hình trên tập test\n    if test_loader:\n        logger.info(\"Đánh giá trên tập Test...\")\n        # Tải mô hình tốt nhất nếu có, nếu không dùng mô hình cuối cùng\n        best_model_path = os.path.join(OUTPUT_DIR, 'best_model.pt')\n        if os.path.exists(best_model_path) and val_loader : # chỉ load best_model nếu có val_loader\n            checkpoint = torch.load(best_model_path, map_location=device)\n            model.load_state_dict(checkpoint['model_state_dict'])\n            logger.info(\"Đã tải mô hình tốt nhất để đánh giá trên tập test.\")\n        else:\n            logger.info(\"Sử dụng mô hình cuối cùng để đánh giá trên tập test (không có mô hình tốt nhất từ validation hoặc không có val set).\")\n\n        test_loss = evaluate(model, test_loader, criterion, device)\n        print(f\"Test Loss: {test_loss:.4f}\")\n\n        test_vi_texts  = [ex[\"source_text\"] for ex in test_dataset]\n        test_lo_texts  = [ex[\"target_text\"] for ex in test_dataset]\n\n        references = [[ref.strip().split()] for ref in test_lo_texts]\n        hypotheses = []\n        for src_sent in test_vi_texts:\n            hyp = translate_sentence(\n                model,\n                src_sent,\n                data_processor.vi_vocab,\n                data_processor.lao_vocab,\n                device,\n                max_length=MAX_LENGTH,\n                source_tokenizer=vi_tokenizer\n            )\n            hypotheses.append(hyp.split())\n        \n        # Compute BLEU and print as a percentage\n        bleu_score = corpus_bleu(references, hypotheses) * 100\n        print(f\"Corpus BLEU: {bleu_score:.4f}\")\n    else:\n        logger.warning(\"Không có dữ liệu test để đánh giá.\")\n\n\n    # Dịch một số câu ví dụ\n    examples = [\n        \"Xin chào, tôi thích ăn đồ ăn Lào.\",\n        \"Cảm ơn bạn rất nhiều.\",\n        \"Tôi đến từ Việt Nam.\",\n        \"Bạn có thể giúp tôi không?\"\n    ]\n    print(\"Một số ví dụ dịch:\")\n    for example in examples:\n        translated = translate_sentence(\n            model,\n            example,\n            data_processor.vi_vocab,\n            data_processor.lao_vocab,\n            device,\n            source_tokenizer=lambda x: x.split()\n        )\n        print(f\"Tiếng Việt: {example}\")\n        print(f\"Tiếng Lào: {translated}\")\n        print(\"-\" * 50)\n\n    return model, data_processor\n\ndef main():\n    \"\"\"Hàm chính để huấn luyện và đánh giá mô hình\"\"\"\n    # Tạo thư mục đầu ra nếu chưa tồn tại\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n\n    # Khởi tạo bộ xử lý dữ liệu\n    data_processor = TranslationDataProcessor()\n\n    try:\n        # Tạo bộ dữ liệu\n        train_dataset, val_dataset, test_dataset = data_processor.create_datasets()\n\n        # Huấn luyện mô hình\n        if len(train_dataset) > 0:\n            # Lưu từ vựng\n            torch.save({\n                'vi_vocab': data_processor.vi_vocab,\n                'lao_vocab': data_processor.lao_vocab\n            }, os.path.join(OUTPUT_DIR, 'vocabularies.pt'))\n            logger.info(\"Đã lưu từ vựng!\")\n\n            model, data_processor = train_model(data_processor, train_dataset, val_dataset, test_dataset)\n        else:\n            logger.error(\"Huấn luyện bị hủy do tập huấn luyện rỗng.\")\n\n    except FileNotFoundError:\n        logger.error(\"Một hoặc nhiều file dữ liệu không được tìm thấy. Vui lòng kiểm tra lại các đường dẫn PATH.\")\n    except AssertionError as e:\n        logger.error(f\"Lỗi Assertion: {e}. Thường do số lượng câu không khớp giữa các file ngôn ngữ.\")\n    except Exception as e:\n        logger.error(f\"Đã xảy ra lỗi không mong muốn: {e}\", exc_info=True)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}